---
layout: post
title: 深度学习一页纸总结
category: 科研
permalink: /2013/07/short-summary-on-deep-learning/
keywords: deep-learning, short summary
---

本文是研究生阶段老板让我在听了邓力教授的深度学习讲座（龙星计划-天津大学）后的总结文档。

# 一、深度学习的定义及优点

深度学习（Deep Learning），或者也可以称作深层结构学习、分层学习是一类机器学习技术。深度学习的概念源自于人工神经网络的研究，有两种定义都能较好地描述深度学习：（1）一种多层模型（如神经网络模型），利用分层的方式训练；（2）一种无监督学习较高层特征表示的方法。
深度学习方法有很多优点:（1）深度学习可以模拟复杂的非线性现象，当然越深的层级也会带来更多的开销。（2）深度学习可以学习分布式特征表示。与传统的局部特征表示不同，分布式特征表示由一系列有可能是统计独立的显著特征组成，与局部泛化的方式相比，基于分布式表示的可区分模式的数目与分布式特征的维数是指数倍的关系。例如在语音识别应用中，某个分布式特征可能是由发音、周边环境等多个可计算的因素共同决定的。（3）此外，深度学习还可以很好地利用大量的非标号数据。我们知道，小孩可以通过现实世界中大量的未标号原始数据来不断学习，我们希望计算机通过深度学习也能拥有这项技能。
深度学习明确突出了特征学习的重要性，目的在于，通过逐层特征变换，将样本在原空间的特征表示变换到一个新特征空间，从而使分类或预测更加容易。

# 二、深度学习的一般方法

首先回顾一个通用的学习方法，通过学习函数f，获取一个由输入单元X到输出标号y的映射。深度学习方法不直接解决这个问题，而是通过学习出隐特征h来为输入X建模，即X→h→y.
整个问题的关键就在于我们如何发掘有用的隐特征，如何解决这个基本问题可以作为深度学习方法分类的一个准则。比如Deep Belief Nets（DBN）使用Restricted Boltzman Machines.


![DBN](http://qiangrw.github.io/images/dbn.png "DBN")
图1. DBN=Stacked RBM

图1是DBN的示例，其训练的关键在于无监督的逐层初始化与有监督的微调（fine-tuning）。对于逐层初始化，每次只训练一层模型，如X→h层或h→y层，实际上是进行了神经网络的权值初始化，这个初始化可以使后续的训练时间大大减少，同时也可以避免训练时陷入局部最优。DBM的每一层都是由RBM构成的，RBM是一种简单的马尔科夫随机场。特别的，它限定了同一隐含层各个单元之间是没有边的，从而简化了模型，使得训练深层网络变为可能。

一种RBMs的简单替代模型是Auto-Encoders。其输出为输入本身，隐含层可以作为一个压缩的特征向量，类似主成分分析，可用于降维处理。此外，Auto
Encoder有很多变种，可以结合领域知识进行建模。


![Auto Encoder](http://qiangrw.github.io/images/auto_encoder.png "Auto Encoder")
图2. Auto Encoder 示例图

# 三、在各个领域的应用情况
深度学习在语音识别、计算机视觉都已经有了很好的应用。例如在语音识别上，MSRA使用Deep
Learning技术将SWDB数据集上的错误率从23%降到13%；深度学习技术在图像检索上的突破也非常显著。相比前两个方向，深度学习在NLP和IR上的效果提升相对较小。目前很多公司也正在探索如何将DL应用到这两个领域。
另一方面，深度学习虽然在工业界取得了较好的实际效果，但是到目前并没有坚实的理论基础支撑，这是为学术界所诟病的。

# 四、小结
深度学习并不是全新的东西，其实就是“多层”神经网络。之前由于其计算复杂度高、容易过拟合等问题一直没能很好地体现其优势。随着计算机硬件的高速发展，以及海量数据的获得，加之以一堆很能提升效果的Trick（如Dropout等），使得深度学习适逢其时，成为一时之热。今后在其他各个领域是否能带来更多惊喜？ 让我们拭目以待。


